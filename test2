import json
from typing import Any, Dict, List

import requests
from app.graph.state import PCPState
from app.services.case_rest import(
    get_case,
    sync_case_from_interaction
)
from app.llm.horizon_client import call_horizon
from app.llm.parsers import (
    llm_validate_no_px_keys, 
    llm_parse_filter_input,
    llm_extract_provider_query_from_assign_text,
    llm_decide_followup_action,
    llm_parse_provider_input,
    llm_parse_zip_and_date,
    llm_parse_no_flow_filters,
    llm_parse_specialist_filters,
    llm_classify_yes_no
)
from app.config import settings
from datetime import datetime, timedelta, date
from langgraph.types import Command, interrupt
from app.services.member_rest import (
    member_search,
    get_active_pcp
)
from app.services.provider_search import(
    get_default_radius_in_miles,
    provider_search_by_name,
    _format_address_from_provider,
    provider_search_by_id,
    provider_generic_search,
    map_language_to_code,
    ProviderSearchAPIError
)
from app.services.soap_client import(
    make_change_family_broker_request,
    build_executeex_envelope,
    call_execute_ex,
    format_date_mmddyyyy,
    extract_short_error
)
from app.graph.call_source import mark_api, mark_llm
from fastapi import FastAPI, HTTPException, status
import logging
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from app.graph.routing import (
    route_after_provider_followup,
    route_after_specialist_completion,
    route_from_menu,
    route_after_specialist_provider_address,
    route_knows_provider,
    route_after_provider_search_results,
    route_after_no_results_offer,
    route_after_npi_run_search,
    route_after_npi_followup,
    route_after_specialist_search,
    route_after_specialist_no_results_offer
)
from app.services.npi_registry import (
    npi_search_by_zip,
    npi_search_by_name,
    normalize_npi_results
)

logger = logging.getLogger("pcp_app")

def node_load_case(state: PCPState) -> PCPState:
    """
    Load case details using InteractionID, filter out px* keys, store in state.
    No interrupt here; continue to menu/start.
    """
    # If already loaded (e.g., resume), don't redo
    if state.get("case_filtered") is not None:
        return state

    interaction_id = (state.get("interaction_id") or "").strip()
    if not interaction_id:
        # If UI didn't send it, keep flow alive but record nothing
        state["case_raw"] = None
        state["case_filtered"] = None
        return state

    try:
        mark_api(state, get_case)
        raw, filtered = sync_case_from_interaction(interaction_id)
        # filtered = _strip_px_keys(raw, prefix="px")
        state["case_raw"] = raw
        state["case_filtered"] = filtered

        # LLM validation
        mark_llm(state)
        validated = llm_validate_no_px_keys(filtered)
        state["case_px_audit"] = validated

        return state

    except Exception as ex:
        logger.exception("Get Case API failed: %s", ex)
        # Do NOT break the existing PCP flow; just store empty and continue
        state["case_raw"] = None
        state["case_filtered"] = None
        return state
    
def node_start(state: PCPState) -> PCPState:
    """
    Initial node: show main menu and interrupt to get user's choice.
    """
    logger.debug("node_start")

    # IMPORTANT: When showing the main menu, always reset transient flow state.
    # This prevents stale Assign-PCP/Specialist state from leaking into a new menu selection.
    for k in [
        # PCP flow
        "termination_reason",
        "knows_provider",
        "raw_provider_input",
        "raw_filter_input",
        "providers_result",
        "last_followup_action",
        "initial_assign_text",
        "provider_id",
        "provider_name",
        "provider_city",
        "provider_state",
        "last_selected_provider_id",
        "selected_provider_snapshot",
        "active_provider_id",
        "active_eff_dt",
        "startingLocationZip",
        "asOfDate",

        # Specialist flow bits
        "flow",
        "specialist_service_specialty",
        "specialist_raw_filter_input",
        "specialist_raw_filter_input",  # safe even if repeated
        "specialist_service_specialty",  # safe even if repeated
    ]:
        state.pop(k, None)

    # Keep NPI reset here too (safe; menu should start clean)
    for k in ["npi_results_payload", "npi_mode", "npi_query", "npi_origin", "npi_target_flow", "provider_id_override"]:
        state.pop(k, None)

    menu_text = (
        "You can choose one of the following options:<br>"
        "1. Assign PCP<br>"
        "2. Search for specialist<br>"
        "3. Search Provider NPI (Web)"
    )
    mark_llm(state)
    try:
        ai_msg = call_horizon(
            "You are a helpful CSR assistant. Ask the member to choose one of the options.",
            menu_text,
        )  
    except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
      
    state["ai_response"] = ai_msg
    state["prompt_title"] = "How can I assist you today?"
    state["prompts"] = settings.DEFAULT_PROMPTS
    state["ai_response_code"] = 100
    state["ai_response_type"] = "Dialog"
    state["stage"] = "MENU"

    # Interrupt, waiting for user choice
    requested = interrupt({
        "prompt": ai_msg,
        "prompts": settings.DEFAULT_PROMPTS,
        "stage": state["stage"],
        "call_source": state.get("call_name") or state.get("call_type"),
    })

    # When resumed:
    state["csr_query"] = str(requested)

    # Save original text; later we can reuse if it already includes provider id /name
    user_choice = (state["csr_query"] or "").strip()

    if user_choice in settings.DEFAULT_PROMPTS:
        state["initial_assign_text"] = ""
    else:
        state["initial_assign_text"] = user_choice
    return state


def node_collect_termination_reason(state: PCPState) -> PCPState:
    logger.debug("node_collect_termination_reason")

    # If already present, just return (safety)
    if state.get("termination_reason"):
        return state
    
    # # Consume the termination reason that was captured in csr_query
    # reason = (state.get("csr_query") or "").strip()
    # if reason:
    #     state["termination_reason"] = reason
    #     state["csr_query"] = ""
    #     return state
    
    # # Safety fallback: if somehow we reached here without a resume value,
    # # route back to asking termination again by leaving termination_reason empty
    # return state
    reason = (state.get("csr_query") or "").strip()
    if not reason:
        return state

    # ✅ Safety: do not treat menu choice as termination reason
    menu_prompts = getattr(settings, "MENU_PROMPTS", None)
    if not isinstance(menu_prompts, list) or not menu_prompts:
        menu_prompts = settings.DEFAULT_PROMPTS

    if reason in menu_prompts:
        state["csr_query"] = ""
        return state

    state["termination_reason"] = reason
    state["csr_query"] = ""
    return state

def node_assign_pcp_ask_termination(state: PCPState) -> PCPState:
    """
    Node used when user says 'Assign PCP' in chat.
    1) Calls get_active_pcp with member_id from state
    2) Extracts Active_Provider_ID
    3) Asks: 'Please select the termination reason for current PCP - <Active_Provider_ID>.'
    4) AIResponseCode = 112
    5) Interrupts to wait for user's termination reason
    """
    logger = logging.getLogger("pcp.assign_pcp")
    logger.debug("node_assign_pcp_ask_termination, state=%s", state)

    #IMPORTANT: If we entered Assign-PCP from a menu selection,
    # wipe transient PCP keys so we NEVER treat "Assign PCP" as termination_reason.
    st = (state.get("stage") or "").strip().upper()
    if st in ("START", "MENU", "GO_MENU"):
        for k in (
            "termination_reason",
            "knows_provider",
            "raw_provider_input",
            "raw_filter_input",
            "providers_result",
            "provider_id",
            "provider_name",
            "provider_city",
            "provider_state",
            "startingLocationZip",
            "asOfDate",
            "last_followup_action",
            "initial_assign_text",
            "last_selected_provider_id",
            "selected_provider_snapshot",
            "provider_id_override",
        ):
            state.pop(k, None)

        # also make sure we do not carry the menu selection forward as a "reason"
        state["csr_query"] = ""

    member_id = state.get("member_id")
    if not member_id:
        # Safety guard
        state["ai_response"] = "Member information is missing. Please start a new conversation."
        state["ai_response_code"] = 500
        state["ai_response_type"] = "Dialog"
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # ----------------------------------------------------------------------
    # If we *don't* have termination_reason yet: fetch active PCP and ask
    # ----------------------------------------------------------------------
    if not state.get("termination_reason"):
        # 1) Call your REST tool: get_active_pcp
        try:
            member_response = member_search(dob = "", mbrId=member_id, firstNm = "", lastNm = "")
            # mark_api(state, member_search) # If we return right after this API call in an error case, this helps
            if isinstance(member_response, list):
                if not member_response:
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="Member not found for the given mbrId."
                    )
                member_payload = member_response[0]
            else:
                member_payload = member_response
            
            state["grgr_ck"] = str(member_payload.get("grgrCk") or member_payload.get("sbsbCk")).strip()
            state["meme_ck"] = str(member_payload.get("memeCk")).strip()
            state["group_id"] = str(member_payload.get("grpId")).strip()
            state["subscriber_id"] = str(member_payload.get("subscriberId")).strip()

            # print("DEBUG get_active_pcp = ", get_active_pcp, type(get_active_pcp))
            active_pcp = get_active_pcp(member_key=state["meme_ck"], grgr_ck=state["grgr_ck"])
            # print("active_pcp: ", active_pcp)
            # mark_api(state, get_active_pcp) # If we return right after this API call in an error case, this helps
            curr_active = active_pcp.get("active") or {}

            # effective date present in active object
            eff = (
                curr_active.get("effectiveDate")
                or curr_active.get("provEffectiveDt")
                or curr_active.get("effDt")
            )
            state["active_eff_dt"] = str(eff).strip() if eff else None

        except Exception as ex:
            logger.exception("get_active_pcp failed: %s", ex)
            mark_api(state, get_active_pcp) # Here, error step shows which API faield
            state["ai_response"] = "Unable to fetch your current PCP details right now. Please try again later."
            state["ai_response_code"] = 500
            state["ai_response_type"] = "Dialog"
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state

        # 2) Extract Provider ID from response (adjust key as per your API)
        #    example keys: 'provId', 'ProviderId', etc.
        active_provider_id = (
            curr_active.get("provId")
            or curr_active.get("providerId")
            or curr_active.get("PCPProviderId")
        )
        # print("active_provider_id: ", active_provider_id)
        state["active_provider_id"] = str(active_provider_id) if active_provider_id else ""

        # 3) Build question including active provider id
        base_question = f"Please select the termination reason for current PCP - {state['active_provider_id']}."

        # 4) Optional: pass through Horizon LLM to keep your 'LLM brain' requirement
        try:
            ai_msg = call_horizon(
                "You are a CSR assistant. Ask the member to select a termination reason using the given sentence. "
                "Keep the provider ID exactly as it is.",
                base_question,
            )
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state    
        mark_llm(state)

        # 5) Populate response fields
        state["ai_response"] = ai_msg
        state["ai_response_code"] = 112          # 112 = Dialog
        state["ai_response_type"] = "Dialog"
        state["prompts"] = []                    # UI will show its own reasons list
        state["stage"] = "WAIT_TERMINATION_REASON"

        # 6) INTERRUPT – return this message to the caller (chat endpoint)
        requested = interrupt({
            "prompt": state["ai_response"],
            "stage": state["stage"],
            "active_provider_id": state["active_provider_id"],
        })

        # When resumed (next /chat call), we capture termination reason:
        # state["termination_reason"] = str(requested)
        # logger.debug("Termination reason captured from interrupt: %s", state["termination_reason"])
        
        # On resume, capture the termination reason into csr_query for the next node
        state["csr_query"] = str(requested).strip()
        return state

    # ----------------------------------------------------------------------
    # Else, termination_reason is already filled (we resumed this node),
    # so we just handoff to the next stage in your flow (ask provider id / yes-no etc.)
    # ----------------------------------------------------------------------
    return state

def node_collect_knows_provider(state: PCPState) -> PCPState:
    logger.debug("node_collect_knows_provider")

    # FREE-FORM SHORTCIRCUIT:
    # If user already provided provider info in the initial menu message
    # (e.g., "Please assign 12345678 as PCP" or "Please assign John, Dallas, TX as PCP"),
    # skip ASK_KNOWS_PROVIDER and go straight to provider search.
    if state.get("knows_provider") is None and not state.get("raw_provider_input"):
        candidate = (state.get("initial_assign_text") or "").strip()
        if candidate:
            parsed = llm_extract_provider_query_from_assign_text(candidate)

            st = parsed.get("search_type")
            pid = (parsed.get("provider_id") or "").strip() if parsed.get("provider_id") else ""
            z = (parsed.get("zip") or "").strip() if parsed.get("zip") else ""
            name = (parsed.get("name") or "").strip() if parsed.get("name") else ""
            city = (parsed.get("city") or "").strip() if parsed.get("city") else ""
            st_code = (parsed.get("state") or "").strip() if parsed.get("state") else ""

            if st == "id" and pid:
                state["knows_provider"] = True
                state["raw_provider_input"] = pid
                state["csr_query"] = pid
                state["initial_assign_text"] = ""  # consume it
                return state

            if st == "zip_only" and z:
                state["knows_provider"] = True
                state["raw_provider_input"] = z
                state["csr_query"] = z
                state["initial_assign_text"] = ""
                return state

            # Name only should also skip YES/NO for free form text
            if (st == "name_city_state" or (st == "unknown" and name)) and (name or city or st_code or z):
                # Build a normalized single string input for downstream LLM parser
                # For name only, normalized will just be the name
                parts = [p for p in [name, city, st_code, z] if p]
                normalized = ", ".join(parts) if parts else candidate

                state["knows_provider"] = True
                state["raw_provider_input"] = normalized
                state["csr_query"] = normalized
                state["initial_assign_text"] = ""
                return state
  
    if state.get("knows_provider") is None:
        system_prompt = (
            "You are a CSR assistant."
            "Write a short, clear question asking the member whether they know"
            "the name or ID of the provider they are looking for."
            "The question should be suitable as a UI title and must be answerable with Yes or No."
            "Return ONLY the question text, without any extra words."
        )
        user_prompt = "Ask the member if they know the name or ID of the provider they are looking for."
        try:
            ai_msg = call_horizon(system_prompt, user_prompt).strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
        mark_llm(state)
        state["ai_response"] = ""
        state["prompt_title"] = ai_msg
        state["prompts"] = ["Yes", "No"]
        state["ai_response_code"] = 101
        state["ai_response_type"] = "AURA"
        state["stage"] = "ASK_KNOWS_PROVIDER"

        requested = interrupt({
            "prompt": ai_msg,
            "prompts": state["prompts"],
            "stage": state["stage"],
        })
        answer = str(requested).strip().lower()
        state["csr_query"] = answer
        state["knows_provider"] = "yes" in answer

        logger.debug("knows_provider captured from interrupt: %s", state["knows_provider"])
        return state
    else:
        return state

def node_collect_provider_input(state: PCPState) -> PCPState:
    logger.debug("node_collect_provider_input")

    if not state.get("raw_provider_input"):
        system_prompt = (
            "You are a CSR assistant helping a member choose a new PCP. "
            "You must produce a short dialog message that will be shown in the AIResponse field. "
            "The message MUST:<br>"
            "- Start with a bold line: 'Ask the below questions:'  "
            "- Then show three bullet points (or dotted list items) in this exact order and wording:  "
            " 1) 'May I know the Provider ID? or Provider Name, City and State?'  "
            " 2) 'Search would be performed based on member's home address. If you would like to search provider at different location, please provide with zip code and address line 1.'  "
            " 3) 'Search will be performed with today's date unless a different date is provided (MM-DD-YYYY).'  "
            "Use simple markdown-style formatting: bold for the first line, and each question on its own line starting with a bullet or a dot. "
            "Return ONLY the formatted text, no explanations."
        )
        user_prompt = "Generate the dialog text exactly as specified, to be displayed to the CSR as instructions."
        try:
            ai_msg = call_horizon(system_prompt, user_prompt).strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
            
        mark_llm(state)
        state["ai_response"] = ai_msg
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = 103
        state["ai_response_type"] = "Dialog"
        state["stage"] = "ASK_PROVIDER_INPUT"

        requested = interrupt({
            "prompt": ai_msg,
            "stage": state["stage"],
        })
        state["raw_provider_input"] = str(requested)
        state["csr_query"] = state["raw_provider_input"]
        return state
    else:
        return state

def node_collect_no_flow_filters(state: PCPState) -> PCPState:
    """
    NO flow:
    Show the HTML question block with default distance inserted,
    AIResponseType=Dialog, AIResponseCode=103, PromptTitle empty,
    Prompts=["Please proceed with the default values."].
    Then interrupt and capture user's input in raw_filter_input.
    """
    logger.debug("node_collect_no_flow_filters")
    mark_llm(state) 

    if state.get("raw_filter_input"):
        return state

    group_id = (state.get("group_id") or "").strip()
    if not group_id:
        state["ai_response"] = "Member details are missing (groupId). Please start a new conversation."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # default distance from CSV (Market=groupId, PractitionerType=PCP)
    default_distance = get_default_radius_in_miles(group_id=group_id, practitioner_type="PCP")
  
    html = (
        "<p><b>Ask the below questions:</b></p>"
        "<ul>"
        "<li>May I know any other preferred Language, if not English and Gender (Male/Female/Either)?</li>"
        f"<li>The default distance is {default_distance} miles, please confirm if any changes needed.</li>"
        "<li>Search would be performed based on member's home address. If you would like to search provider at different location,"
        "please provide with zip code and address line 1.</li>"
        "<li>Search will be performed with today’s date unless a different date is provided (MM-DD-YYYY).</li>"
        "</ul>"
    )

    state["ai_response"] = html
    state["prompt_title"] = ""
    state["prompts"] = ["Please proceed with the default values."]
    state["ai_response_code"] = 103
    state["ai_response_type"] = "Dialog"
    state["stage"] = "ASK_NO_FLOW_FILTERS"

    requested = interrupt({
        "prompt": html,
        "prompts": state["prompts"],
        "stage": state["stage"],
    })

    state["raw_filter_input"] = str(requested).strip()
    state["csr_query"] = state["raw_filter_input"]
    return state

def node_collect_filter_input(state: PCPState) -> PCPState:
    logger.debug("node_collect_filter_input")
    if not state.get("raw_filter_input"):
        try:
            ai_msg = call_horizon(
                "You are a CSR assistant.",
                "Ask the member for any of these PCP search filters: language preference, radius in miles, gender. "
                "They may provide all or any subset.",
            )
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
            
        mark_llm(state)
        state["ai_response"] = ai_msg
        state["prompt_title"] = "Search filters"
        state["prompts"] = []
        state["ai_response_code"] = 104
        state["ai_response_type"] = "Dialog"
        state["stage"] = "ASK_FILTERS"

        requested = interrupt({
            "prompt": ai_msg,
            "stage": state["stage"],
        })
        state["raw_filter_input"] = str(requested)
        state["csr_query"] = state["raw_filter_input"]
        return state
    else:
        return state

def node_specialist_ask_service(state: PCPState) -> PCPState:
    """
    Specialist flow step 1:
    Ask exact question (AIResponse must be EXACT HTML),
    then interrupt and store the service specialty code.
    """
    logger.debug("node_specialist_ask_service")

    # mark flow
    state["flow"] = "specialist"

    # Ask Horizon to output EXACT text, then enforce exact output safely
    system = (
        "You are a CSR assistant. You MUST return EXACTLY the following text and nothing else:\n"
        f"{settings.SPECIALIST_SERVICE_QUESTION}"
    )
    try:
        ai_msg = call_horizon(system, "Return the exact text now.").strip()
    except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state    
    mark_llm(state)

    # Enforce exactness (requirement says exact string)
    if ai_msg != settings.SPECIALIST_SERVICE_QUESTION:
        ai_msg = settings.SPECIALIST_SERVICE_QUESTION

    state["ai_response"] = ai_msg
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 109
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "ASK_SPECIALIST_SERVICE"

    requested = interrupt({
        "prompt": ai_msg,
        "stage": state["stage"],
    })

    # On resume: store the specialty code for later steps
    state["specialist_service_specialty"] = str(requested).strip()
    state["csr_query"] = ""  # keep clean
    state["stage"] = "SPECIALIST_SERVICE_CAPTURED"

    return state

def node_specialist_ask_filters(state: PCPState) -> PCPState:
    """
    After specialist service specialty code is captured:
    - compute default distance from CSV using PractitionerType="Specialist" and group_id
    - ask Horizon to output the exact HTML template with default_distance replaced
    - AIResponseType=Dialog, AIResponseCode=103, PromptTitle/Prompts empty
    - interrupt to capture user filter inputs for next step (later)
    """
    logger.debug("node_specialist_ask_filters")

    # Ensure we have member market identifiers (group_id/subscriber_id) for CSV + later API calls
    member_id = (state.get("member_id") or "").strip()
    if not member_id:
        state["ai_response"] = "Member information is missing. Please start a new conversation."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    if not (state.get("group_id") and state.get("subscriber_id") and state.get("meme_ck") and state.get("grgr_ck")):
        try:
            member_response = member_search(dob="", mbrId=member_id, firstNm="", lastNm="")
            if isinstance(member_response, list):
                if not member_response:
                    raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Member not found.")
                member_payload = member_response[0]
            else:
                member_payload = member_response

            state["grgr_ck"] = str(member_payload.get("grgrCk") or member_payload.get("sbsbCk") or "").strip()
            state["meme_ck"] = str(member_payload.get("memeCk") or "").strip()
            state["group_id"] = str(member_payload.get("grpId") or "").strip()
            state["subscriber_id"] = str(member_payload.get("subscriberId") or "").strip()
        except Exception as ex:
            logger.exception("member_search failed in specialist flow: %s", ex)
            mark_api(state, member_search)
            state["ai_response"] = "Unable to fetch member details right now. Please try again later."
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"            
            return state

    group_id = (state.get("group_id") or "").strip()
    if not group_id:
        state["ai_response"] = "Member group information is missing. Please start a new conversation."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # Default distance from CSV for Specialist
    try:
        default_distance = get_default_radius_in_miles(group_id=group_id, practitioner_type="Specialist")
    except Exception as ex:
        logger.exception("Default distance lookup failed: %s", ex)
        state["ai_response"] = "Unable to determine the default distance right now. Please try again later."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    expected_html = settings.SPECIALIST_FILTERS_TEMPLATE.replace("<<default_distance>>", str(default_distance))

    # Ask Horizon to produce EXACT HTML (then enforce exactness to meet UI contract)
    system = (
        "You are a CSR assistant.\n"
        "Return EXACTLY the following HTML (no extra spaces, no explanation, no markdown fences):\n"
        f"{expected_html}"
    )
    try:
        ai_msg = call_horizon(system, "Return the exact HTML now.").strip()
    except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
        
    mark_llm(state)
    if ai_msg != expected_html:
        ai_msg = expected_html  # enforce contract

    state["ai_response"] = ai_msg
    state["ai_response_type"] = "Dialog"
    state["ai_response_code"] = 103
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "ASK_SPECIALIST_FILTERS"

    requested = interrupt({
        "prompt": ai_msg,
        "stage": state["stage"],
    })

    # store the filter text for next step (generic search later)
    state["specialist_raw_filter_input"] = str(requested).strip()
    state["csr_query"] = ""
    state["stage"] = "SPECIALIST_FILTERS_CAPTURED"
    return state

def node_specialist_provider_address(state: PCPState) -> PCPState:
    """
    After specialist provider grid is shown, user selects a provider id and asks for address.
    Return address JSON in AIResponse, and mark conversation as completed (inquiry only).
    """
    logger.debug("node_specialist_provider_address")

    providers = state.get("providers_result") or []
    if not providers:
        state["ai_response"] = "No providers are available in the current result. Please start a new search."
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = 404
        state["ai_response_type"] = "AURA"
        state["stage"] = "ERROR"
        return state

    # We should already have the user's message in csr_query (resume value)
    user_msg = (state.get("csr_query") or "").strip()
    if not user_msg:
        requested = interrupt({"prompt": "", "stage": "WAIT_SPECIALIST_PROVIDER_ACTION"})
        state["csr_query"] = str(requested).strip()
        user_msg = state["csr_query"]

    # Use existing LLM helper to understand intent + provider id
    decision = llm_decide_followup_action(user_msg, providers)
    mark_llm(state)
    action = decision.get("action")
    #print("decision : ", decision, "action: ", action)
    pid = decision.get("provider_id")

    if action == "provider_id_only":
        mark_llm(state)
        state["ai_response"] = "Please check the response that you have provided"
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "SPECIALIST_PROVIDER_FOLLOWUP_RESPONSE"
        state["last_followup_action"] = "provider_id_only"
        
        # Stop the graph here so nothing overwrites the state
        requested = interrupt({
            "prompt": state["ai_response"],
            "stage": state["stage"],
        })

        # Store next user message for next turn 
        state["csr_query"] = str(requested).strip()
        return state

    # Specialist flow supports ONLY address inquiry (not assignment)
    if action != "address" or not pid:
        state["ai_response"] = (
            "Please provide a Provider ID and ask for its address (for example: 'address of 12345678')."
        )
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = 110
        state["ai_response_type"] = "AURA"
        state["stage"] = "SPECIALIST_NEED_ADDRESS_CLARIFICATION"
        return state

    # Find chosen provider from providers_result
    chosen = None
    for p in providers:
        cand = (
            p.get("providerId")
            or p.get("provId")
            or p.get("ProviderID")
            or p.get("id")
        )
        if str(cand).strip() == str(pid).strip():
            chosen = p
            break

    if not chosen:
        state["ai_response"] = "I couldn't find that Provider ID in the current results. Please pick a Provider ID from the list."
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = 110
        state["ai_response_type"] = "AURA"
        state["stage"] = "SPECIALIST_NEED_ADDRESS_CLARIFICATION"
        return state

    prov_id = str(chosen.get("providerId") or pid or "").strip()
    addr_payload = {
        "providerAddress": [{
            "ProviderID": prov_id,
            "AddressType": chosen.get("addressType"),
            "AddressLine1": chosen.get("address1") or chosen.get("addressLine1"),
            "AddressLine2": chosen.get("address2") or chosen.get("addressLine2"),
            "City": chosen.get("city"),
            "State": chosen.get("state"),
            "Zip": chosen.get("zip") or chosen.get("zipCode"),
            "Country": chosen.get("country") or chosen.get("county"),
            "Phone": chosen.get("phone"),
            "Fax": chosen.get("fax"),
            "EffectiveDate": chosen.get("effectiveDate"),
            "TerminationDate": chosen.get("terminationDate"),
        }]
    }

    # Final inquiry response (completed)
    state["ai_response"] = json.dumps(addr_payload, default=str, separators=(",", ":"))
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 110
    state["prompt_title"] = "Do you need further assistance?"
    state["prompts"] = ["Yes", "No"]
    state["stage"] = "COMPLETED"

    requested = interrupt({
        "prompt": state["ai_response"],
        "stage": "SPECIALIST_COMPLETED",
        "prompt_title": state["prompt_title"],
        "prompts": state["prompts"],
        "ai_response_code": state["ai_response_code"],
        "ai_response_type": state["ai_response_type"],
    })

    # store next yes/no answer for routing
    state["csr_query"] = str(requested).strip()
    return state

def node_provider_id_only_warning(state: PCPState) -> PCPState:
    """
    If user sends only Provider ID without asking address/assign,
    show the warning message and STOP here (interrupt).
    Next message resumes back to provider_interaction.
    """
    mark_llm(state)
    msg = "Please check the response that you have provided."

    state["ai_response"] = msg
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 101
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "PROVIDER_ID_ONLY_WARNING"

    # IMPORTANT: interrupt each time (no fall-through)
    requested = interrupt({
        "prompt": msg,
        "stage": state["stage"],
    })

    # capture the next user input so provider_interaction can process it
    state["csr_query"] = str(requested).strip()
    state["last_followup_action"] = None
    return state


def node_provider_interaction(state: PCPState) -> PCPState:
    """
    After showing the provider list JSON, this node uses interrupt + LLM
    to interpret whether user wants address or PCP assignment.
    """
    logger.debug("node_provider_interaction")
    providers = state.get("providers_result") or []
    if not providers:
        state["ai_response"] = "No providers are available in the current result. Please start a new search."
        state["prompt_title"] = "No providers found"
        state["prompts"] = []
        state["ai_response_code"] = 404
        state["ai_response_type"] = "Dialog"
        state["stage"] = "ERROR"
        return state

    # Ask user what they want to do next, if csr_query not yet captured
    if not state.get("csr_query"):
        try:
            ai_msg = call_horizon(
                "You are a CSR assistant.",
                "The member has seen the provider search JSON. Ask them what they want to do next: "
                "for example, ask for the address of a provider, or assign a specific provider as PCP.",
            )
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
            
        mark_llm(state)
        state["ai_response"] = ai_msg
        state["prompt_title"] = "Next action"
        state["prompts"] = []
        state["ai_response_code"] = 108
        state["ai_response_type"] = "Dialog"
        state["stage"] = "PROVIDER_ACTION"

        requested = interrupt({
            "prompt": ai_msg,
            "stage": state["stage"],
        })
        state["csr_query"] = str(requested)

    # Use LLM to understand provider action
    decision = llm_decide_followup_action(state["csr_query"], providers)
    mark_llm(state)
    action = decision.get("action")
    pid = decision.get("provider_id")

    # If user sent ONLY provider id (no text)
    if action == "provider_id_only":
        state["last_followup_action"] = "provider_id_only"
        return state
    
    chosen = None
    if pid:
        for p in providers:
            for k in ("providerId", "provider_id", "id"):
                if str(p.get(k)) == str(pid):
                    chosen = p
                    break
            if chosen:
                break

    if action == "address" and chosen:
        prov_id = str(chosen.get("providerId") or "")
        addr_payload = {
            "providerAddress": [{
                "ProviderID": prov_id,
                "AddressType": chosen.get("addressType"),
                "AddressLine1": chosen.get("address1"),
                "AddressLine2": chosen.get("address2"),
                "City": chosen.get("city"),
                "State": chosen.get("state"),
                "Zip": chosen.get("zip"),
                "Country": chosen.get("country") or chosen.get("county"),
                "Phone": chosen.get("phone"),
                "Fax": chosen.get("fax"),
                "EffectiveDate": chosen.get("effectiveDate"),
                "TerminationDate": chosen.get("terminationDate"),
            }]
        }

        state["ai_response"] = json.dumps(addr_payload, default=str, separators=(",", ":"))
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = 108
        state["ai_response_type"] = "AURA"
        state["stage"] = "PROVIDER_FOLLOWUP_RESPONSE"
        state["last_followup_action"] = "address"
        return state
        
    if action == "assign_pcp" and chosen:
        pid_final = str(chosen.get("providerId") or pid or "").strip()

        state["last_selected_provider_id"] = pid_final
        state["selected_provider_snapshot"] = chosen
        state["last_followup_action"] = "assign_pcp"
        state["stage"] = "READY_TO_UPDATE_PCP"

        # No response here; next node will do SOAP + confirmation
        state["ai_response"] = ""
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = ""
        state["prompts"] = []
        return state

    # If other / not clear
    mark_llm(state)
    state["ai_response"] = (
        "I could not understand which provider or action you meant. "
        "Please mention if you want the address of a provider or to assign a provider as PCP, "
        "including the Provider ID."
    )
    state["prompt_title"] = "Clarification"
    state["prompts"] = []
    state["ai_response_code"] = 110
    state["ai_response_type"] = "Dialog"
    state["stage"] = "PROVIDER_FOLLOWUP_RESPONSE"
    state["last_followup_action"] = "other"
    return state

def node_run_provider_search(state: PCPState) -> PCPState:
    logger.debug("node_run_provider_search")

    if state.get("providers_result"):
        return state
    
    providers: List[Dict[str, Any]] = []

    # -----------------------------------------------------
    # Case 1 : member knows provider id
    # -----------------------------------------------------
    if state.get("knows_provider"):
        override_id = (state.get("provider_id_override") or "").strip()
        if override_id:
            # Treat override as provider-id search
            parsed = {"search_type": "id", "provider_id": override_id}
        else:
            parsed = llm_parse_provider_input(state.get("raw_provider_input") or "")

        search_type = parsed.get("search_type")

        if search_type == "name_city_state":
            raw_text = state.get("raw_provider_input") or ""

            # Basic name/city/state from existing LLM parser
            name = parsed.get("name") or ""
            city = parsed.get("city") or ""
            st = parsed.get("state") or ""

            state["provider_name"] = name
            state["provider_city"] = city
            state["provider_state"] = st

            # Let Horizon extract optional ZIP and as-of date
            extra = llm_parse_zip_and_date(raw_text)
            zip_code = extra.get("zip")
            as_of_date = extra.get("as_of_date")

            state["startingLocationZip"] = zip_code
            state["asOfDate"] = as_of_date

            # Derive lastName and firstName from provider name
            last_name = ""
            first_name = None
            if name:
                parts = name.split()
                if len(parts) >= 1:
                    last_name = parts[0]
                if len(parts) >= 2:
                    first_name = parts[1]

            # # Use full name for providerName param (if your API uses it)
            # full_provider_name = name or None

            # member_id = state.get("member_id", "")

            # Call normalized name-search service
            mark_api(state, provider_search_by_name)
            providers = provider_search_by_name(
                last_name=last_name or "",
                group_id=state.get("group_id", ""),
                subscriber_id=state.get("subscriber_id", ""),
                member_id="",
                first_name=first_name,
                provider_name="",
                city=city or None,
                state=st or None,
                startingLocationZip=zip_code,
                asOfDate=as_of_date,
            ) 

            if not providers:
                # Ask via Horizon LLM (no hardcode message content)
                search_basis = (state.get("raw_provider_input") or state.get("raw_filter_input") or "").strip()
                if not search_basis:
                    search_basis = state.get("csr_query") or ""

                sys = (
                    "You are a CSR assistant.\n"
                    "The internal provider directory search returned no results.\n"
                    "Ask the user if they would like to try the NPI Web search instead.\n"
                    "Return ONLY the question text (no JSON, no markdown fences).\n"
                    "The question must mention that no record was found for the provided input.\n"
                )
                user = f"No provider record found for: {search_basis}"
                try:
                    ai_msg = call_horizon(sys, user).strip()
                except requests.exceptions.ReadTimeout:
                    # Don't break flow: show a recoverable error and wait for next user input
                    state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
                    state["ai_response_type"] = "AURA"
                    state["ai_response_code"] = 500
                    state["prompt_title"] = ""
                    state["prompts"] = []
                    state["stage"] = "ERROR"
                    return state  
                  
                mark_llm(state)

                state["ai_response"] = ""
                state["ai_response_type"] = "AURA"
                state["ai_response_code"] = 101
                state["prompt_title"] = ai_msg
                state["prompts"] = ["Yes", "No"]
                state["npi_origin"] = "fallback"
                state["stage"] = "PCP_NO_RESULTS_OFFER_NPI"
                # also clear old npi state (safety)
                state.pop("npi_results_payload", None)
                state.pop("npi_mode", None)
                state.pop("npi_query", None)
                state.pop("npi_followup_text", None)

                requested = interrupt({
                    "prompt": "",  # UI uses PromptTitle + Prompts here
                    "stage": state["stage"],
                    "prompt_title": state["prompt_title"],
                    "prompts": state["prompts"],
                    "ai_response_code": state["ai_response_code"],
                    "ai_response_type": state["ai_response_type"],
                })

                # store user's answer (yes/no) for the next routing node
                state["csr_query"] = str(requested).strip()
                return state           

            # Build grid JSON exactly like the ID case
            grid_list: List[Dict[str, Any]] = []
            for p in providers:
                prov_id = (
                    p.get("providerId")
                    or p.get("provId")
                    or p.get("ProviderID")
                )
                name_val = (
                    p.get("name")
                    or p.get("providerName")
                    or p.get("fullName")
                    or ""
                )

                addr = _format_address_from_provider(p)

                # Network
                raw_network = (
                    p.get("networkStatus")
                    or p.get("network")
                    or p.get("Network")
                )
                net_str = ""
                if raw_network:
                    raw_up = str(raw_network).upper()
                    if raw_up in ("IN", "IN NETWORK"):
                        net_str = "In Network"
                    elif raw_up in ("OUT", "OUT NETWORK"):
                        net_str = "Out Network"
                    else:
                        net_str = str(raw_network)

                # IsAcceptingNewMembers
                is_accpeting = p.get("isAcceptingNewMembers")

                # PCPAssnInd
                pcp_ind = p.get("pcpAssnInd") or p.get("PCPAssnInd")

                # Distance
                dist = (
                    p.get("distance_mi")
                    or p.get("distanceInMiles")
                    or p.get("Distance_mi")
                )

                grid_list.append({
                    "ProviderID": str(prov_id) if prov_id is not None else "",
                    "Name": str(name_val),
                    "Address": addr,
                    "Network": net_str,
                    "IsAcceptingNewMembers": is_accpeting,
                    "PCPAssnInd": pcp_ind,
                    "DistanceInMiles": dist,
                })

            response_payload = {"providers": grid_list}

            state["providers_result"] = providers
            state["ai_response"] = json.dumps(response_payload, default=str, separators=(",", ":"))
            state["prompt_title"] = "Select a provider id to update"
            state["prompts"] = []
            state["ai_response_code"] = 107
            state["ai_response_type"] = "AURA"
            state["stage"] = "SHOW_PROVIDER_LIST"

            requested = interrupt({
                "prompt": state["ai_response"],
                "stage": state["stage"],
            })

            state["csr_query"] = str(requested)
            return state
        
        if search_type == "zip_only":
            raw_text = state.get("raw_provider_input") or ""

            # ZIP from provider input parser
            zip_code = parsed.get("zip")
            if not zip_code:
                # safety fallback: treat the entire text as zip if LLM didn’t fill it
                zip_code = raw_text.strip()

            # As-of-date from LLM (YYYYMMDD or None)
            extra = llm_parse_zip_and_date(raw_text)
            as_of_date = extra.get("as_of_date")

            state["startingLocationZip"] = zip_code
            state["asOfDate"] = as_of_date

            # Mandatory fields for generic search
            group_id = state.get("group_id", "")
            subscriber_id = state.get("subscriber_id", "")
            if not group_id or not subscriber_id:
                state["ai_response"] = "Member details are missing (groupId/subscriberId). Please start a new conversation."
                state["prompt_title"] = "Error"
                state["prompts"] = []
                state["ai_response_code"] = 500
                state["ai_response_type"] = "Dialog"
                state["stage"] = "ERROR"
                return state

            # Radius from Default Distance.csv (Market=groupId, PractitionerType=PCP)
            try:
                radius = get_default_radius_in_miles(group_id=group_id, practitioner_type="PCP")
            except Exception as ex:
                state["ai_response"] = f"Unable to determine default search radius: {ex}"
                state["prompt_title"] = "Error"
                state["prompts"] = []
                state["ai_response_code"] = 500
                state["ai_response_type"] = "Dialog"
                state["stage"] = "ERROR"
                return state

            # Call generic search (normalized providers list)
            try:
                mark_api(state, provider_generic_search)
                providers = provider_generic_search(
                    group_id=group_id,
                    subscriber_id=subscriber_id,
                    radius_in_miles=radius,
                    startingLocationZip=str(zip_code)[:5],
                    asOfDate=as_of_date,
                )
            except ProviderSearchAPIError as e:
                # Show backend detail to user
                state["providers_result"] = []
                state["ai_response"] = e.message  # <-- this is backend exceptions[0].detail
                state["prompt_title"] = ""
                state["prompts"] = []
                state["ai_response_code"] = e.status_code or 500
                state["ai_response_type"] = "AURA"
                state["stage"] = "ERROR"

                requested = interrupt({
                "stage": state["stage"],
                "prompt": state["ai_response"],
                "prompt_title": state["prompt_title"],
                "prompts": state["prompts"],
                "ai_response_code": state["ai_response_code"],
                "ai_response_type": state["ai_response_type"],
                })
                state["csr_query"] = str(requested).strip()
                return state   

            if not providers:
                # Ask via Horizon LLM (no hardcode message content)
                search_basis = (state.get("raw_provider_input") or state.get("raw_filter_input") or "").strip()
                if not search_basis:
                    search_basis = state.get("csr_query") or ""

                sys = (
                    "You are a CSR assistant.\n"
                    "The internal provider directory search returned no results.\n"
                    "Ask the user if they would like to try the NPI Web search instead.\n"
                    "Return ONLY the question text (no JSON, no markdown fences).\n"
                    "The question must mention that no record was found for the provided input.\n"
                )
                user = f"No provider record found for: {search_basis}"
                try:
                    ai_msg = call_horizon(sys, user).strip()
                except requests.exceptions.ReadTimeout:
                    # Don't break flow: show a recoverable error and wait for next user input
                    state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
                    state["ai_response_type"] = "AURA"
                    state["ai_response_code"] = 500
                    state["prompt_title"] = ""
                    state["prompts"] = []
                    state["stage"] = "ERROR"
                    return state    
                mark_llm(state)

                state["ai_response"] = ""
                state["ai_response_type"] = "AURA"
                state["ai_response_code"] = 101
                state["prompt_title"] = ai_msg
                state["prompts"] = ["Yes", "No"]
                state["npi_origin"] = "fallback"
                state["stage"] = "PCP_NO_RESULTS_OFFER_NPI"
                # also clear old npi state (safety)
                state.pop("npi_results_payload", None)
                state.pop("npi_mode", None)
                state.pop("npi_query", None)
                state.pop("npi_followup_text", None)

                requested = interrupt({
                    "prompt": "",  # UI uses PromptTitle + Prompts here
                    "stage": state["stage"],
                    "prompt_title": state["prompt_title"],
                    "prompts": state["prompts"],
                    "ai_response_code": state["ai_response_code"],
                    "ai_response_type": state["ai_response_type"],
                })

                # store user's answer (yes/no) for the next routing node
                state["csr_query"] = str(requested).strip()
                return state        
            
            # Build grid JSON exactly like provider-id case
            grid_list: List[Dict[str, Any]] = []
            for p in providers:
                prov_id = p.get("providerId") or ""
                name_val = p.get("name") or ""
                addr = _format_address_from_provider(p)

                raw_network = p.get("networkStatus") or ""
                raw_up = str(raw_network).upper()
                if raw_up in ("IN", "IN NETWORK"):
                    net_str = "In Network"
                elif raw_up in ("OUT", "OUT NETWORK"):
                    net_str = "Out Network"
                else:
                    net_str = str(raw_network) if raw_network else ""

                is_accpeting = p.get("isAcceptingNewMembers")

                pcp_ind = p.get("pcpAssnInd") or p.get("PCPAssnInd")

                dist = p.get("distance_mi") or p.get("distanceInMiles")

                grid_list.append({
                    "ProviderID": str(prov_id),
                    "Name": str(name_val),
                    "Address": addr,
                    "Network": net_str,
                    "IsAcceptingNewMembers": is_accpeting,
                    "PCPAssnInd": pcp_ind,
                    "DistanceInMiles": dist,
                })

            response_payload = {"providers": grid_list}

            state["providers_result"] = providers
            state["ai_response"] = json.dumps(response_payload, default=str, separators=(",", ":"))
            state["prompt_title"] = "Select a provider id to update"
            state["prompts"] = []
            state["ai_response_code"] = 107
            state["ai_response_type"] = "AURA"
            state["stage"] = "SHOW_PROVIDER_LIST"

            requested = interrupt({"prompt": state["ai_response"], "stage": state["stage"]})
            state["csr_query"] = str(requested)
            return state 
        # Provider ID path
        else:
            pid = parsed.get("provider_id") or ""
            state["provider_id"] = pid
            # clear override once consumed
            state["provider_id_override"] = None
            # print("date : ", state.get("asOfDate", ""))
            mark_api(state, provider_search_by_id)
            providers = provider_search_by_id(
                id = pid, 
                group_id = state.get("group_id", ""),
                subscriber_id = state.get("subscriber_id", ""),
                asOfDate = state.get("asOfDate", ""),
                )
            
            if not providers:
                # Ask via Horizon LLM (no hardcode message content)
                search_basis = (state.get("raw_provider_input") or state.get("raw_filter_input") or "").strip()
                if not search_basis:
                    search_basis = state.get("csr_query") or ""

                sys = (
                    "You are a CSR assistant.\n"
                    "The internal provider directory search returned no results.\n"
                    "Ask the user if they would like to try the NPI Web search instead.\n"
                    "Return ONLY the question text (no JSON, no markdown fences).\n"
                    "The question must mention that no record was found for the provided input.\n"
                )
                user = f"No provider record found for: {search_basis}"
                try:
                    ai_msg = call_horizon(sys, user).strip()
                except requests.exceptions.ReadTimeout:
                    # Don't break flow: show a recoverable error and wait for next user input
                    state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
                    state["ai_response_type"] = "AURA"
                    state["ai_response_code"] = 500
                    state["prompt_title"] = ""
                    state["prompts"] = []
                    state["stage"] = "ERROR"
                    return state    
                
                mark_llm(state)

                state["ai_response"] = ""
                state["ai_response_type"] = "AURA"
                state["ai_response_code"] = 101
                state["prompt_title"] = ai_msg
                state["prompts"] = ["Yes", "No"]
                state["npi_origin"] = "fallback"
                state["stage"] = "PCP_NO_RESULTS_OFFER_NPI"
                # also clear old npi state (safety)
                state.pop("npi_results_payload", None)
                state.pop("npi_mode", None)
                state.pop("npi_query", None)
                state.pop("npi_followup_text", None)

                requested = interrupt({
                    "prompt": "",  # UI uses PromptTitle + Prompts here
                    "stage": state["stage"],
                    "prompt_title": state["prompt_title"],
                    "prompts": state["prompts"],
                    "ai_response_code": state["ai_response_code"],
                    "ai_response_type": state["ai_response_type"],
                })

                # store user's answer (yes/no) for the next routing node
                state["csr_query"] = str(requested).strip()
                return state 
            
            # print("raw result : ", providers)
            # Now build the AIResponse JSON in the requried shape using providers
            grid_list: List[Dict[str, Any]] = []
            for p in providers:
                prov_id = (
                    p.get("providerId")
                    or p.get("provId")
                    or p.get("ProviderID")
                    or state.get("provider_id")
                )
                name_val = (
                    p.get("name")
                    or p.get("providerName")
                    or p.get("fullName")
                )

                # Reuse existing helper to build address steing
                addr = _format_address_from_provider(p)
                # print("Address : ", addr)
                # Network in/out
                raw_network = (
                    p.get("networkStatus")
                    or p.get("network")
                    or p.get("Network")
                )
                net_str = ""
                if raw_network:
                    raw_up = str(raw_network).upper()
                    if "IN" in raw_up and "OUT" not in raw_up:
                        net_str = "In Network"
                    elif "OUT" in raw_up:
                        net_str = "Out Network"
                    else:
                        # Fallback to whatever text we have
                        net_str = str(raw_network)
                else:
                    net_str = ""

                is_accpeting = p.get("isAcceptingNewMembers")

                pcp_ind = p.get("pcpAssnInd") or p.get("PCPAssnInd")

                # Distance in miles
                dist = (
                    p.get("distance_mi")
                    or p.get("distanceInMiles")
                    or p.get("Distance_mi")
                )

                grid_list.append({
                    "ProviderID": str(prov_id) if prov_id is not None else "",
                    "Name": str(name_val) if name_val is not None else "",
                    "Address": addr,
                    "Network": net_str,
                    "IsAcceptingNewMembers": is_accpeting,
                    "PCPAssnInd": pcp_ind,
                    "DistanceInMiles": dist
                })

            response_payload = {
                "providers": grid_list
            }

            state["providers_result"] = providers # keep raw list for later steps
            state["ai_response"] = json.dumps(response_payload, default=str, separators=(',', ':'))
            state["prompt_title"] = "Select a provider id to update"
            state["prompts"] = []
            state["ai_response_code"] = 107
            state["ai_response_type"] = "AURA"
            state["stage"] = "SHOW_PROVIDER_LIST"

            # Interrupt to show this JSON grid to UI and wait for next user action
            requested = interrupt({
                "prompt": state["ai_response"],
                "stage": state["stage"],
            })

            # Next user message (e.g., asking for address) will be stored here
            state["csr_query"] = str(requested)
            return state
        
    # -----------------------------------------------------
    # Case 2 : member does not know provider id
    #          (filters path)
    # -----------------------------------------------------
    else:
        # NO flow -> provider_generic_search
        raw_text = (state.get("raw_filter_input") or "").strip()

        group_id = (state.get("group_id") or "").strip()
        subscriber_id = (state.get("subscriber_id") or "").strip()

        if not group_id or not subscriber_id:
            state["ai_response"] = "Member details are missing (groupId/subscriberId). Please start a new conversation."
            state["prompt_title"] = ""
            state["prompts"] = []
            state["ai_response_code"] = 500
            state["ai_response_type"] = "AURA"
            state["stage"] = "ERROR"
            return state

        default_radius = get_default_radius_in_miles(group_id=group_id, practitioner_type="PCP")

        parsed = llm_parse_no_flow_filters(raw_text)
        # Defaults
        radius = default_radius
        provider_lang = ""
        provider_sex = ""
        zip_code = None
        as_of_date = None

        if parsed.get("use_defaults"):
            # keep defaults only
            pass
        else:
            # language
            provider_lang = map_language_to_code(parsed.get("language"))
            # print("provdr lang :",provider_lang)
            # gender
            g = parsed.get("gender")
            if g in ("M", "F"):
                provider_sex = g

            # zip
            z = parsed.get("zip")
            if z and str(z).isdigit() and len(str(z)) == 5:
                zip_code = str(z)

            # date (YYYYMMDD expected from LLM)
            as_of_date = parsed.get("as_of_date")

            # radius override
            r = parsed.get("radius_in_miles")
            if isinstance(r, (int, float)) and r > 0:
                radius = int(r)
        try:
            mark_api(state, provider_generic_search)
            providers = provider_generic_search(
                group_id=group_id,
                subscriber_id=subscriber_id,
                radius_in_miles=radius,
                startingLocationZip=zip_code or "",
                asOfDate=as_of_date,                 # service should apply today's date if None/empty
                providerLanguage=provider_lang,      # must be supported in provider_search.py
                providerSex=provider_sex,            # must be supported in provider_search.py
            )   
        except ProviderSearchAPIError as e:
            # Show backend detail to user
            state["providers_result"] = []
            state["ai_response"] = e.message  # <-- this is backend exceptions[0].detail
            state["prompt_title"] = ""
            state["prompts"] = []
            state["ai_response_code"] = e.status_code or 500
            state["ai_response_type"] = "AURA"
            state["stage"] = "ERROR"

            requested = interrupt({
            "stage": state["stage"],
            "prompt": state["ai_response"],
            "prompt_title": state["prompt_title"],
            "prompts": state["prompts"],
            "ai_response_code": state["ai_response_code"],
            "ai_response_type": state["ai_response_type"],
            })
            state["csr_query"] = str(requested).strip()
            return state
        
        if not providers:
                # Ask via Horizon LLM (no hardcode message content)
                search_basis = (state.get("raw_provider_input") or state.get("raw_filter_input") or "").strip()
                if not search_basis:
                    search_basis = state.get("csr_query") or ""

                sys = (
                    "You are a CSR assistant.\n"
                    "The internal provider directory search returned no results.\n"
                    "Ask the user if they would like to try the NPI Web search instead.\n"
                    "Return ONLY the question text (no JSON, no markdown fences).\n"
                    "The question must mention that no record was found for the provided input.\n"
                )
                user = f"No provider record found for: {search_basis}"
                try:
                    ai_msg = call_horizon(sys, user).strip()
                except requests.exceptions.ReadTimeout:
                    # Don't break flow: show a recoverable error and wait for next user input
                    state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
                    state["ai_response_type"] = "AURA"
                    state["ai_response_code"] = 500
                    state["prompt_title"] = ""
                    state["prompts"] = []
                    state["stage"] = "ERROR"
                    return state 
                    
                mark_llm(state)

                state["ai_response"] = ""
                state["ai_response_type"] = "AURA"
                state["ai_response_code"] = 101
                state["prompt_title"] = ai_msg
                state["prompts"] = ["Yes", "No"]
                state["npi_origin"] = "fallback"
                state["stage"] = "PCP_NO_RESULTS_OFFER_NPI"
                # also clear old npi state (safety)
                state.pop("npi_results_payload", None)
                state.pop("npi_mode", None)
                state.pop("npi_query", None)
                state.pop("npi_followup_text", None)

                requested = interrupt({
                    "prompt": "",  # UI uses PromptTitle + Prompts here
                    "stage": state["stage"],
                    "prompt_title": state["prompt_title"],
                    "prompts": state["prompts"],
                    "ai_response_code": state["ai_response_code"],
                    "ai_response_type": state["ai_response_type"],
                })

                # store user's answer (yes/no) for the next routing node
                state["csr_query"] = str(requested).strip()
                return state      

        # Build SAME grid JSON shape as your other flows
        grid_list: List[Dict[str, Any]] = []
        for p in (providers or []):
            prov_id = p.get("providerId") or ""
            name_val = p.get("name") or ""
            addr = _format_address_from_provider(p)

            raw_network = p.get("networkStatus") or ""
            raw_up = str(raw_network).upper()
            if raw_up in ("IN", "IN NETWORK"):
                net_str = "In Network"
            elif raw_up in ("OUT", "OUT NETWORK"):
                net_str = "Out Network"
            else:
                net_str = str(raw_network) if raw_network else ""

            grid_list.append({
                "ProviderID": str(prov_id),
                "Name": str(name_val),
                "Address": addr,
                "Network": net_str,
                "IsAcceptingNewMembers": p.get("isAcceptingNewMembers"),
                "PCPAssnInd": p.get("pcpAssnInd") or p.get("PCPAssnInd"),
                "DistanceInMiles": p.get("distance_mi") or p.get("distanceInMiles"),
            })

        response_payload = {"providers": grid_list}

        state["providers_result"] = providers
        state["ai_response"] = json.dumps(response_payload, default=str, separators=(",", ":"))
        state["prompt_title"] = "Select a provider id to update"
        state["prompts"] = []
        state["ai_response_code"] = 107
        state["ai_response_type"] = "AURA"
        state["stage"] = "SHOW_PROVIDER_LIST"

        requested = interrupt({
            "prompt": state["ai_response"], 
            "stage": state["stage"]
            })
        state["csr_query"] = str(requested)
        return state

def node_run_specialist_generic_search(state: PCPState) -> PCPState:
    """
    Specialist flow:
    - Use stored specialist_service_specialty
    - Parse specialist_raw_filter_input (any combo)
    - Apply defaults (distance from CSV for Specialist + today's YYYYMMDD if date missing)
    - Call provider_generic_search(serviceSpecialty=...)
    - Return provider grid JSON in AIResponse (AURA, 107), PromptTitle/Prompts empty
    """
    logger.debug("node_run_specialist_generic_search")
    
    # ------------------------------------------------------------------
    # Resume handler: user answered the "No results -> NPI?" question
    # ------------------------------------------------------------------
    if (state.get("stage") or "").strip().upper() == "SPECIALIST_NO_RESULTS_OFFER_NPI":
        ans = llm_classify_yes_no((state.get("csr_query") or "").strip())

        if ans == "yes":
            # state["npi_origin"] = "fallback"
            # state["npi_target_flow"] = "specialist"
            state["csr_query"] = ""
            state["stage"] = "GO_NPI"
            return state

        if ans == "no":
            state["csr_query"] = ""
            state["stage"] = "GO_MENU"
            return state

        # unknown -> ask again (same offer screen)
        # requested = interrupt({
        #     "prompt": "",  # UI uses prompt_title for AURA
        #     "stage": "SPECIALIST_NO_RESULTS_OFFER_NPI",
        #     "prompt_title": state.get("prompt_title") or "",
        #     "prompts": state.get("prompts") or ["Yes", "No"],
        #     "ai_response_code": state.get("ai_response_code") or 101,
        #     "ai_response_type": state.get("ai_response_type") or "AURA",
        # })
        # state["csr_query"] = str(requested).strip()
        return state
    
    # If already have results, don't re-run
    if state.get("providers_result"):
        return state

    group_id = (state.get("group_id") or "").strip()
    subscriber_id = (state.get("subscriber_id") or "").strip()
    specialty = (state.get("specialist_service_specialty") or "").strip()

    if not group_id or not subscriber_id:
        state["ai_response"] = "Member details are missing (groupId/subscriberId). Please start a new conversation."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    if not specialty:
        state["ai_response"] = "Service specialty code is missing. Please enter the service specialty code."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 109
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ASK_SPECIALTY"
        return state

    # Defaults
    default_radius = get_default_radius_in_miles(group_id=group_id, practitioner_type="Specialist")
    today_yyyymmdd = datetime.now().strftime("%Y%m%d")

    raw_text = (state.get("specialist_raw_filter_input") or "").strip()
    parsed = llm_parse_specialist_filters(raw_text)
    print("parsed: ",parsed)
    radius = int(default_radius)
    provider_lang = ""
    provider_sex = ""
    zip_code = ""
    as_of_date = today_yyyymmdd

    if parsed.get("use_defaults"):
        # keep defaults only
        pass
    else:
        # language -> providerLanguage
        provider_lang = map_language_to_code(parsed.get("language"))

        # gender -> providerSex (M/F only)
        g = parsed.get("gender")
        if g in ("M", "F"):
            provider_sex = g

        # zip -> startingLocationZip
        z = parsed.get("zip")
        if z and str(z).isdigit() and len(str(z)) == 5:
            zip_code = str(z)

        # date -> asOfDate (YYYYMMDD)
        d = parsed.get("as_of_date")
        if isinstance(d, str) and d.strip():
            as_of_date = d.strip()

        # radius override
        r = parsed.get("radius_in_miles")
        if isinstance(r, (int, float)) and r > 0:
            radius = int(r)

    try:
        # IMPORTANT: provider_generic_search must accept these named params
        mark_api(state, provider_generic_search)
        providers = provider_generic_search(
            group_id=group_id,
            subscriber_id=subscriber_id,
            radius_in_miles=radius,
            startingLocationZip=zip_code,
            asOfDate=as_of_date,
            providerLanguage=provider_lang,
            providerSex=provider_sex,
            serviceSpecialty=specialty,
        ) 
    except ProviderSearchAPIError as e:
        # Show backend detail to user
        state["providers_result"] = []
        state["ai_response"] = e.message  # <-- this is backend exceptions[0].detail
        state["prompt_title"] = ""
        state["prompts"] = []
        state["ai_response_code"] = e.status_code or 500
        state["ai_response_type"] = "AURA"
        state["stage"] = "ERROR"

        requested = interrupt({
        "stage": state["stage"],
        "prompt": state["ai_response"],
        "prompt_title": state["prompt_title"],
        "prompts": state["prompts"],
        "ai_response_code": state["ai_response_code"],
        "ai_response_type": state["ai_response_type"],
        })
        state["csr_query"] = str(requested).strip()
        return state 

    if not providers:
        # mark that we are entering NPI offer flow from specialist
        state["providers_result"] = None
        state["npi_origin"] = "fallback"
        state["npi_target_flow"] = "specialist"

        # Clear any old NPI state
        for k in ("npi_results_payload", "npi_mode", "npi_query", "provider_id_override"):
            state.pop(k, None)

        # IMPORTANT: route to offer node (do not re-ask filters)
        state["stage"] = "SPECIALIST_NO_RESULTS_OFFER_NPI"
        return state

    # Build grid JSON (same shape)
    grid_list: List[Dict[str, Any]] = []
    for p in (providers or []):
        prov_id = p.get("providerId") or ""
        name_val = p.get("name") or ""
        addr = _format_address_from_provider(p)

        raw_network = p.get("networkStatus") or ""
        raw_up = str(raw_network).upper()
        if raw_up in ("IN", "IN NETWORK"):
            net_str = "In Network"
        elif raw_up in ("OUT", "OUT NETWORK"):
            net_str = "Out Network"
        else:
            net_str = str(raw_network) if raw_network else ""

        grid_list.append({
            "ProviderID": str(prov_id),
            "Name": str(name_val),
            "Address": addr,
            "Network": net_str,
            "IsAcceptingNewMembers": p.get("isAcceptingNewMembers"),
            "PCPAssnInd": p.get("pcpAssnInd") or p.get("PCPAssnInd"),
            "DistanceInMiles": p.get("distance_mi") or p.get("distanceInMiles"),
        })

    response_payload = {"providers": grid_list}

    state["providers_result"] = providers
    state["ai_response"] = json.dumps(response_payload, default=str, separators=(",", ":"))
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 107
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "SHOW_SPECIALIST_PROVIDER_LIST"

    requested = interrupt({"prompt": state["ai_response"], "stage": state["stage"]})
    state["csr_query"] = str(requested)
    return state

def node_specialist_no_results_offer(state: PCPState) -> PCPState:
    """
    Show: no results found -> ask if user wants NPI search (Yes/No).
    Keep UI contract same as PCP: question in prompt_title, ai_response empty.
    """
    logger.debug("node_specialist_no_results_offer")

    # Build question with Horizon (no hardcode)
    sys = (
        "You are a CSR assistant.\n"
        "The specialist provider search returned no results.\n"
        "Ask the user if they would like to try the NPI Web search instead.\n"
        "Return ONLY the question text (no JSON, no markdown).\n"
        "The question must mention that no record was found for the provided input.\n"
    )
    search_basis = (state.get("specialist_raw_filter_input") or "").strip()
    user = f"No specialist provider record found for: {search_basis}"

    try:
        offer_q = call_horizon(sys, user).strip()
    except requests.exceptions.ReadTimeout:
        state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    mark_llm(state)

    state["ai_response"] = ""
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 101
    state["prompt_title"] = offer_q
    state["prompts"] = ["Yes", "No"]
    state["stage"] = "SPECIALIST_NO_RESULTS_OFFER_NPI"

    requested = interrupt({
        "prompt": "",
        "stage": state["stage"],
        "prompt_title": state["prompt_title"],
        "prompts": state["prompts"],
        "ai_response_code": state["ai_response_code"],
        "ai_response_type": state["ai_response_type"],
    })

    state["csr_query"] = str(requested).strip()
    return state

def node_specialist_post_completion(state: PCPState) -> PCPState:
    """
    After specialist address is shown with Yes/No prompts, route:
    - Yes -> route to RETURN_TO_MENU node
    - No  -> closing message + END
    """
    logger.debug("node_specialist_post_completion")

    txt = (state.get("csr_query") or "").strip().lower()

    # Let Horizon interpret yes/no semantically (no hardcoded matching only)
    sys = (
        "You classify whether the user response means YES or NO.\n"
        "Return ONLY JSON: {\"answer\":\"yes\"|\"no\"|\"unknown\"}\n"
    )
    try:
        raw = call_horizon(sys, txt).strip()
    except requests.exceptions.ReadTimeout:
        #Don't break flow: show a recoverable error and wait for next user input
        state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state 
        
    mark_llm(state)
    if raw.startswith("```"):
        raw = raw.strip("`")
        i = raw.find("{")
        if i != -1:
            raw = raw[i:]
    ans = "unknown"
    try:
        ans = (json.loads(raw).get("answer") or "unknown").lower()
    except Exception:
        ans = "unknown"

    if ans == "no":
        state["ai_response"] = "We're closing your request-feel free to return if you need anything else."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "CLOSED"
        return state

    # YES or unknown -> send to menu (same behavior as start)
    # reset specialist-specific fields (keep member details/thread)
    state["providers_result"] = None
    # state["specialist_service_specialty"] = None
    # state["specialist_raw_filter_input"] = None
    state["csr_query"] = ""   # menu will interrupt and refill
    state["stage"] = "GO_MENU"
    return state

def node_return_to_menu(state: PCPState) -> PCPState:
    """
    Emits the START menu payload (AIResponse empty) and interrupts.
    This is used when user says YES after Specialist inquiry completion.
    """
    logger.debug("node_return_to_menu")

    # IMPORTANT: Clear NPI flow state so a fresh NPI selection starts from ASK_MODE next time
    state.pop("npi_results_payload", None)
    state.pop("npi_mode", None)
    state.pop("npi_query", None)

    #  Clear Assign-PCP flow state so re-selecting "Assign PCP" starts from termination reason again
    # (Keep thread_id/member_id/interaction_id/case_* intact)
    for k in (
        "termination_reason",
        "knows_provider",
        "raw_provider_input",
        "raw_filter_input",
        "providers_result",
        "last_followup_action",
        "provider_id",
        "provider_name",
        "provider_city",
        "provider_state",
        "startingLocationZip",
        "asOfDate",
        "initial_assign_text",
        "active_provider_id",
        "active_eff_dt",
        "selected_provider_snapshot",
        "last_selected_provider_id",
        # if we added these for NPI fallback integration:
        "npi_origin",
        "npi_target_flow",
        "provider_id_override",
    ):
        state.pop(k, None)

    # Pull from config when available (avoid hardcoding text in code)
    menu_title = getattr(settings, "MENU_PROMPT_TITLE", "How can I assist you today?")
    menu_prompts = getattr(settings, "MENU_PROMPTS", None)
    if not isinstance(menu_prompts, list) or not menu_prompts:
        menu_prompts = settings.DEFAULT_PROMPTS

    # Exact UI payload
    state["ai_response"] = ""
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 101
    state["prompt_title"] = menu_title
    state["prompts"] = menu_prompts
    state["stage"] = "START"
    mark_llm(state)

    # Interrupt so /chat returns immediately with menu
    requested = interrupt({
        "prompt": "",
        "stage": "RETURN_TO_MENU",
        "prompt_title": menu_title,
        "prompts": menu_prompts,
        "ai_response_code": 101,
        "ai_response_type": "AURA",
    })

    # Resume value becomes the next menu selection
    state["csr_query"] = str(requested).strip()
    return state

def node_wait_next_followup(state: PCPState) -> PCPState:
    """
    Keeps the conversation alive after showing address/warning/etc.
    Interrupts to wait for the next user message, then stores it into csr_query.
    """
    mark_llm(state)
    requested = interrupt({
        "prompt": "",                 # IMPORTANT: empty prompt; UI will display prior ai_response
        "stage": "WAIT_NEXT_FOLLOWUP"
    })

    state["csr_query"] = str(requested)
    return state

def node_update_pcp(state: PCPState) -> PCPState:
    """
    Executes PCP update:
      1) terminate current PCP via SOAP (term_dt=today, eff_dt=active effective date)
      2) add new PCP via SOAP (eff_dt=tomorrow, term_dt empty)
      3) verify via get_active_pcp
      4) return confirmation in PromptTitle (AIResponse empty)
    """
    if not (make_change_family_broker_request and build_executeex_envelope and call_execute_ex and extract_short_error):
        state["ai_response"] = "SOAP services are not configured."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        state["last_followup_action"] = "error"
        return state

    new_pid = str(state.get("last_selected_provider_id") or "").strip()
    if not new_pid:
        state["ai_response"] = "Unable to identify the provider to assign. Please select a Provider ID from the list."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "PROVIDER_FOLLOWUP_RESPONSE"
        state["last_followup_action"] = "other"
        return state

    meme_ck = (state.get("meme_ck") or "").strip()
    grgr_ck = (state.get("grgr_ck") or "").strip()
    curr_pid = (state.get("active_provider_id") or "").strip()
    trsn = (state.get("termination_reason") or "").strip()

    #print("meme_ck:", meme_ck, "grgr_ck:", grgr_ck, "curr_pid:", curr_pid, "trsn:", trsn)

    if not (meme_ck and grgr_ck and trsn):
        state["ai_response"] = "Missing required member/termination details to update PCP."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        state["last_followup_action"] = "error"
        return state

    today_dt = datetime.now().date()
    today_mmddyyyy = format_date_mmddyyyy(today_dt)
    tomorrow_dt = today_dt + timedelta(days=1)
    tommorrow_mmddyyyy = format_date_mmddyyyy(tomorrow_dt)
    
    # Termination effective date must come from active PCP
    active_eff = (state.get("active_eff_dt") or "").strip()

    prev_eff_mmddyyyy = format_date_mmddyyyy(active_eff) if active_eff else tommorrow_mmddyyyy

    # Config values (not hardcoded)
    pcp_type = getattr(settings, "pcpType", None) or getattr(settings, "pcp_type", None)
    mctr_orsn = getattr(settings, "mctrOrsn", None) or getattr(settings, "mctr_orsn", None)

    if not pcp_type or not mctr_orsn:
        state["ai_response"] = "PCP_TYPE / MCTR_ORSN missing from settings."
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        state["last_followup_action"] = "error"
        return state

    try:
        if curr_pid != "":
            # print("inside termination if")
            # 1) TERMINATE CURRENT PCP
            term_req = make_change_family_broker_request(
                grgr_ck=grgr_ck,
                meme_ck=meme_ck,
                pcp_type=pcp_type,
                prpr_id=curr_pid,
                eff_dt_mmddyyyy=prev_eff_mmddyyyy,          # from active PCP
                term_dt_mmddyyyy=today_mmddyyyy,            # today
                mctr_trsn=trsn,             # stored termination reason
                mctr_orsn=mctr_orsn,         # from config
            )
            # print("term req : ", term_req)
            term_env = build_executeex_envelope(term_req)
            try:
                mark_api(state, call_execute_ex)
                resp_term = call_execute_ex(term_env)
                #print("response terminate : ", resp_term)
            except Exception as te:
                short = extract_short_error(str(te))
                raise RuntimeError(f"Terminate step failed: {short}") from te

        # 2) ADD NEW PCP
        add_req = make_change_family_broker_request(
            grgr_ck=grgr_ck,
            meme_ck=meme_ck,
            pcp_type=pcp_type,
            prpr_id=new_pid,
            eff_dt_mmddyyyy=tommorrow_mmddyyyy,          # tomorrow
            term_dt_mmddyyyy="",                 # empty
            mctr_trsn="",               # empty
            mctr_orsn="",               # empty
        )
        # print("add req : ", add_req)
        add_env = build_executeex_envelope(add_req)
        try:
            mark_api(state, call_execute_ex)
            resp = call_execute_ex(add_env)
            #print("resp: ", resp)
        except Exception as ae:
            short = extract_short_error(str(ae))
            raise RuntimeError(f"Assign step failed: {short}") from ae

        # 3) VERIFY
        # mark_api(state, get_active_pcp)
        verify = get_active_pcp(member_key=meme_ck, grgr_ck=grgr_ck)
        active = (verify.get("active") or {}) if isinstance(verify, dict) else {}
        #print("active : ", active)
        verified_pid = (
            active.get("provId")
            or active.get("providerId")
            or active.get("PCPProviderId")
        )
        verified_pid = str(verified_pid).strip() if verified_pid else ""
        # print("verified pid : ", verified_pid)
        # print("new pid : ", new_pid)
        if verified_pid != new_pid:
            raise RuntimeError("PCP update could not be verified. Please try again.")

        # 4) Build confirmation message in PromptTitle (bold values)
        snap = state.get("selected_provider_snapshot") or {}
        name = snap.get("name") or snap.get("providerName") or f"{new_pid}"
        phone = snap.get("phone") or ""
        # full address from your existing formatter
        addr = _format_address_from_provider(snap) if snap else ""

        # Display effective date as MM/DD/YYYY
        eff_disp = format_date_mmddyyyy(tomorrow_dt)
        #print("snap : ", snap, " name : ", name, " phone : ", phone, " addr : ", addr," eff disp : ", eff_disp)
        msg = (
            "New PCP has assigned:<br><br>"
            f"Name: <b>{name}</b>.<br>"
            f"Address: <b>{addr}</b>.<br>"
            f"Phome Number: <b>{phone}</b>.<br>"
            f"Effective Date: <b>{eff_disp}</b>.<br><br>"
            "Please allow upto 7 calendar days to receive your new card.<br><br>"
            "Do you need further assistance?"
        )

        state["ai_response"] = ""
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = msg
        state["prompts"] = ["Appointment Scheduling", "Confirmation Fax"]
        state["stage"] = "COMPLETED"
        state["last_followup_action"] = "assign_pcp"
        return state

    except Exception as ex:
        state["ai_response"] = f"An error occurred while updating PCP: {ex}"
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        state["last_followup_action"] = "error"
        return state

def node_npi_ask_mode(state: PCPState) -> PCPState:
    """
    Ask user whether they want to search NPI by Zip Code or Name.
    Deterministic routing: no LLM.
    """
    logger.debug("node_npi_ask_mode")

    # IMPORTANT: Alwasy reset NPI flow when user enters it from menu
    state.pop("npi_results_payload", None)
    state.pop("npi_query", None)
    state.pop("npi_mode", None)

    # If already chosen (resume safety), skip asking again
    if state.get("npi_mode") in ("zip", "name"):
        return state

    state["ai_response"] = ""
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 101
    state["prompt_title"] = "Search Provider NPI (Web): search by Zip Code or Name?"
    state["prompts"] = ["Zip Code", "Name"]
    state["stage"] = "NPI_ASK_MODE"

    requested = interrupt({
        "prompt": "",
        "stage": state["stage"],
        "prompt_title": state["prompt_title"],
        "prompts": state["prompts"],
    })

    # Deterministic mapping
    choice = str(requested).strip().lower()
    if "zip" in choice:
        state["npi_mode"] = "zip"
    elif "name" in choice:
        state["npi_mode"] = "name"
    else:
        state["npi_mode"] = None  # fallback

    # If not already set by fallback, default to menu
    if not state.get("npi_origin"):
        state["npi_origin"] = "menu"
    if not state.get("npi_target_flow"):
        state["npi_target_flow"] = "pcp"   # default; fallback will override to "specialist"

    # clear csr_query so next node doesn't misread it
    state["csr_query"] = ""
    return state


def node_npi_ask_query(state: PCPState) -> PCPState:
    """
    Ask for zip or name input depending on npi_mode.
    """
    if state.get("npi_query"):
        return state

    mode = state.get("npi_mode")
    if mode == "zip":
        question = "Please enter the Zip Code to search the NPI registry (e.g., 10001 or 10001-1234)."
    elif mode == "name":
        question = "Please enter the Provider Name to search the NPI registry (e.g., 'john' or 'Amy Pandya')."
    else:
        # If somehow mode is missing, re-ask mode
        state["stage"] = "NPI_ASK_MODE"
        return state

    state["ai_response"] = question
    state["ai_response_type"] = "Dialog"
    state["ai_response_code"] = 103
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "NPI_ASK_QUERY"

    requested = interrupt({
        "prompt": question,
        "stage": state["stage"],
    })

    state["npi_query"] = str(requested).strip()
    state["csr_query"] = ""
    return state

def node_npi_run_search(state: PCPState) -> PCPState:
    """
    NPI Web flow:
      - mode in state["npi_mode"] = "zip" | "name"
      - query in state["npi_query"]
      - Calls NPI registry service
      - Responds with JSON in AIResponse (ONLY Name/NPI/Specialty/Address/Phone)
      - Interrupts with stage "NPI_SHOW_RESULTS"
    """
    logger.debug("node_npi_run_search")

    # If already have results cached, ONLY reuse if you're still in NPI_SHOW_RESULTS stage.
    # (When you return to menu, node_return_to_menu clears these keys.)
    if state.get("npi_results_payload"):
        payload = state["npi_results_payload"]
        state["ai_response"] = json.dumps(payload, default=str, separators=(",", ":"))
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = getattr(settings, "NPI_RESULTS_CODE", 107)
        state["prompt_title"] = getattr(settings, "NPI_RESULTS_PROMPT_TITLE", "")
        state["prompts"] = getattr(settings, "NPI_RESULTS_PROMPTS", [])
        state["stage"] = "NPI_SHOW_RESULTS"

        requested = interrupt({
            "prompt": state["ai_response"],
            "stage": state["stage"],
            "prompt_title": state["prompt_title"],
            "prompts": state["prompts"],
            "ai_response_code": state["ai_response_code"],
            "ai_response_type": state["ai_response_type"],
        })
        state["csr_query"] = str(requested).strip()
        return state

    mode = (state.get("npi_mode") or "").strip().lower()
    query = (state.get("npi_query") or "").strip()

    # Safety: if missing mode/query, bounce to your earlier nodes via interrupt (no breaking)
    if mode not in ("zip", "name"):
        state["ai_response"] = ""
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = getattr(settings, "NPI_MODE_PROMPT_TITLE", "")
        state["prompts"] = getattr(settings, "NPI_MODE_PROMPTS", ["Zip Code", "Name"])
        state["stage"] = "NPI_ASK_MODE"

        requested = interrupt({
            "prompt": "",
            "stage": state["stage"],
            "prompt_title": state["prompt_title"],
            "prompts": state["prompts"],
        })
        state["csr_query"] = str(requested).strip()
        return state

    if not query:
        state["ai_response"] = ""
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = getattr(settings, "NPI_QUERY_PROMPT_TITLE", "")
        state["prompts"] = getattr(settings, "NPI_QUERY_PROMPTS", [])
        state["stage"] = "NPI_ASK_QUERY"

        requested = interrupt({
            "prompt": "",
            "stage": state["stage"],
            "prompt_title": state["prompt_title"],
            "prompts": state["prompts"],
        })
        state["csr_query"] = str(requested).strip()
        return state

    # -------- Call services --------
    try:
        raw_results: List[Dict[str, Any]] = []

        if mode == "zip":
            mark_api(state, npi_search_by_zip)
            raw_results = npi_search_by_zip(query)
        else:
            mark_api(state, npi_search_by_name)
            raw_results = npi_search_by_name(query)

        # Normalize to 5 fields only
        providers = [normalize_npi_results(p) for p in (raw_results or []) if isinstance(p, dict)]
       
    except Exception as ex:
        logger.exception("NPI search failed: %s", ex)
        err_msg = getattr(settings, "NPI_ERROR_MESSAGE", "Unable to fetch NPI results right now. Please try again.")
        state["ai_response"] = err_msg
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # Payload (no raw provider dump)
    payload: Dict[str, Any] = {
            "providers": providers,
        }

    state["npi_results_payload"] = payload
    state["ai_response"] = json.dumps(payload, default=str, separators=(",", ":"))
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = getattr(settings, "NPI_RESULTS_CODE", 107)

    origin = (state.get("npi_origin") or "menu").strip().lower()

    if origin == "fallback":
        # Horizon must generate instruction text (no hardcode)
        sys = (
            "You are a CSR assistant.\n"
            "The user is looking at NPI registry results and must choose next step.\n"
            "Write a short PromptTitle that asks them to either:\n"
            "- enter an NPI number from the list to search providers by id, OR\n"
            "- ask for the address of a provider from the list.\n"
            "Return ONLY the title text."
        )
        user = "Generate the prompt title for selecting an NPI or requesting address."
        try:
            followup_title = call_horizon(sys, user).strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state   
          
        mark_llm(state)

        state["prompt_title"] = followup_title
        state["prompts"] = []   # free text
        state["stage"] = "NPI_SHOW_RESULTS"

        requested = interrupt({
            "prompt": state["ai_response"],         # JSON results shown in AIResponse
            "stage": state["stage"],
            "prompt_title": state["prompt_title"],  # Horizon title
            "prompts": state["prompts"],
            "ai_response_code": state["ai_response_code"],
            "ai_response_type": state["ai_response_type"],
            "menu_after": False,                    # IMPORTANT
        })

        # user will type NPI / address request next
        state["csr_query"] = str(requested).strip()
        return state

    # origin == "menu" (keep existing behavior)
    state["prompt_title"] = getattr(settings, "NPI_RESULTS_PROMPT_TITLE", "")
    state["prompts"] = getattr(settings, "NPI_RESULTS_PROMPTS", [])
    state["stage"] = "NPI_SHOW_RESULTS"

    requested = interrupt({
        "prompt": state["ai_response"],
        "stage": state["stage"],
        "prompt_title": state["prompt_title"],
        "prompts": state["prompts"],
        "ai_response_code": state["ai_response_code"],
        "ai_response_type": state["ai_response_type"],
        "menu_after": True,                         # IMPORTANT
    })

    state["csr_query"] = str(requested).strip()
    return state   

def node_pcp_no_results_route(state: PCPState) -> PCPState:
    """
    This node runs AFTER we asked user:
      'No record found... do you want NPI web search?'

    It doesn't interrupt. It just prepares state so the graph routes
    to either NPI flow or menu via conditional edges.
    """
    logger.debug("node_pcp_no_results_route")

    # Defensive cleanup so we don't keep reusing stale provider results
    state["providers_result"] = None
    state["raw_provider_input"] = None
    state["raw_filter_input"] = None

    # Keep csr_query as user's yes/no answer for routing function
    return state

def node_npi_followup_action(state: PCPState) -> PCPState:
    """
    After NPI results in fallback mode:
    - user provides an NPI number OR asks address
    - if NPI number -> call provider_search_by_id(id=<NPI>) via existing provider search flow
    - if address -> return address JSON for that selected NPI record (from NPI results payload)
    """
    logger.debug("node_npi_followup_action")

    results = (state.get("npi_results_payload") or {}).get("providers") or []
    user_msg = (state.get("csr_query") or "").strip()

    if not user_msg:
        # keep waiting if somehow empty
        requested = interrupt({
            "prompt": state.get("ai_response", ""),
            "stage": "NPI_SHOW_RESULTS",
            "prompt_title": state.get("prompt_title", ""),
            "prompts": [],
        })
        state["csr_query"] = str(requested).strip()
        return state

    # Ask Horizon to classify the user's intent and extract NPI if present.
    sys = (
        "You interpret a user response after seeing NPI registry results.\n"
        "Return ONLY valid JSON:\n"
        "{\n"
        '  "action": "select_npi" | "address" | "other",\n'
        '  "npi": string | null\n'
        "}\n"
        "Rules:\n"
        "- If the message contains an NPI number (10 digits), action=select_npi and set npi.\n"
        "- If the user asks for address/location, action=address and set npi if present.\n"
        "- Otherwise action=other.\n"
    )
    try:
        raw = call_horizon(sys, user_msg).strip()
    except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
        
    mark_llm(state)
    if raw.startswith("```"):
        raw = raw.strip("`")
        i = raw.find("{")
        if i != -1:
            raw = raw[i:]

    action = "other"
    npi = None
    try:
        parsed = json.loads(raw)
        action = (parsed.get("action") or "other").strip()
        npi = parsed.get("npi")
    except Exception:
        action = "other"
        npi = None

    # normalize npi string
    npi_str = str(npi).strip() if npi else ""

    if action == "address":
        # Find matching provider in the NPI providers list
        chosen = None
        for p in results:
            if isinstance(p, dict) and str(p.get("NPI") or "").strip() == npi_str:
                chosen = p
                break

        if not chosen:
            # Horizon clarification (no hardcode)
            sys2 = (
                "You are a CSR assistant. Ask the user to provide an NPI number from the shown list "
                "so you can return the address details. Return ONLY the question text."
            )
            try:
                msg = call_horizon(sys2, user_msg).strip()
            except requests.exceptions.ReadTimeout:
                # Don't break flow: show a recoverable error and wait for next user input
                state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
                state["ai_response_type"] = "AURA"
                state["ai_response_code"] = 500
                state["prompt_title"] = ""
                state["prompts"] = []
                state["stage"] = "ERROR"
                return state
            
            mark_llm(state)
            state["ai_response"] = msg
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 101
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "NPI_SHOW_RESULTS"
            requested = interrupt({"prompt": msg, "stage": state["stage"]})
            state["csr_query"] = str(requested).strip()
            return state

        addr_payload = {
            "providerAddress": [{
                "NPI": chosen.get("NPI", ""),
                "Name": chosen.get("Name", ""),
                "Address": chosen.get("Address", ""),
                "Phone": chosen.get("Phone", ""),
            }]
        }

        state["ai_response"] = json.dumps(addr_payload, default=str, separators=(",", ":"))
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 110
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "NPI_ADDRESS_RESULT"

        requested = interrupt({"prompt": state["ai_response"], "stage": state["stage"]})
        state["csr_query"] = str(requested).strip()
        return state

    if action == "select_npi" and npi_str:
        # Route into your existing provider-id flow, but pass NPI as the "id"
        state["provider_id_override"] = npi_str

        # Clear any previous provider results so node_run_provider_search runs
        state["providers_result"] = None

        # Decide target flow
        tgt = (state.get("npi_target_flow") or "pcp").strip().lower()
        state["stage"] = "NPI_SELECTED"

        # Stop NPI loop state so it doesn't replay
        state.pop("npi_results_payload", None)
        state.pop("npi_mode", None)
        state.pop("npi_query", None)

        # If specialist fallback, we do NOT set knows_provider/raw_provider_input for PCP flow
        # We will route to specialist-id-search node
        if tgt == "specialist":
            return state
        
        # PCP flow default (existing behavior)
        state["knows_provider"] = True
        state["raw_provider_input"] = npi_str

        # # IMPORTANT: stop NPI loop state so it doesn't repeat results
        # state.pop("npi_results_payload", None)
        # state.pop("npi_mode", None)
        # state.pop("npi_query", None)
        # state.pop("npi_followup_text", None)

        return state

    # Otherwise ask again (Horizon)
    sys3 = (
        "You are a CSR assistant. The user must either:\n"
        "- enter an NPI number from the shown list to search provider by id, OR\n"
        "- ask for the address of a provider using its NPI.\n"
        "Return ONLY the instruction text."
    )
    try:
        msg = call_horizon(sys3, user_msg).strip()
    except requests.exceptions.ReadTimeout:
        # Don't break flow: show a recoverable error and wait for next user input
        state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state
        
    mark_llm(state)

    state["ai_response"] = msg
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 101
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "NPI_SHOW_RESULTS"

    requested = interrupt({"prompt": msg, "stage": state["stage"]})
    state["csr_query"] = str(requested).strip()
    return state

def node_run_specialist_id_search(state: PCPState) -> PCPState:
    """
    Specialist fallback after NPI selection:
      - provider_id_override contains NPI (10-digit)
      - calls provider_search_by_id(id=<NPI>, group_id/subscriber_id/asOfDate same as existing)
      - shows grid using stage SHOW_SPECIALIST_PROVIDER_LIST
      - next node remains specialist_provider_address (existing)
    """
    logger.debug("node_run_specialist_id_search")

    pid = (state.get("provider_id_override") or "").strip()
    if not pid:
        # if missing, bounce back to NPI mode safely
        state["stage"] = "NPI_ASK_MODE"
        return state

    # Clear override after consuming so it does not repeat
    state["provider_id_override"] = None

    group_id = (state.get("group_id") or "").strip()
    subscriber_id = (state.get("subscriber_id") or "").strip()

    if not group_id or not subscriber_id:
        # Horizon error message (no hardcode)
        sys = (
            "You are a CSR assistant. Member identifiers are missing. "
            "Return a short message asking the user to restart the conversation. Return ONLY the text."
        )
        try:
            msg = call_horizon(sys, "Generate the message.").strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state    
        
        mark_llm(state)

        state["ai_response"] = msg
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # Call your existing provider-by-id API using NPI as id param
    try:
        mark_api(state, provider_search_by_id)
        providers = provider_search_by_id(
            id=pid,
            group_id=group_id,
            subscriber_id=subscriber_id,
            asOfDate=state.get("asOfDate", ""),
        )
    except Exception as ex:
        logger.exception("Specialist provider_search_by_id failed: %s", ex)
        sys = (
            "You are a CSR assistant. The system could not fetch provider results right now. "
            "Return a short apology + retry suggestion. Return ONLY the text."
        )
        try:
            msg = call_horizon(sys, str(ex)).strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state
            
        mark_llm(state)

        state["ai_response"] = msg
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 500
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "ERROR"
        return state

    # If still empty, optionally keep NPI loop (Horizon text)
    if not providers:
        sys = (
            "You are a CSR assistant. The selected NPI did not return any provider record in the internal directory. "
            "Ask the user to try another NPI from the list or search again. Return ONLY the text."
        )
        try:
            msg = call_horizon(sys, pid).strip()
        except requests.exceptions.ReadTimeout:
            # Don't break flow: show a recoverable error and wait for next user input
            state["ai_response"] = getattr(settings, "TIMEOUT_ERROR_MESSAGE", "Request timed out. Please try again.")
            state["ai_response_type"] = "AURA"
            state["ai_response_code"] = 500
            state["prompt_title"] = ""
            state["prompts"] = []
            state["stage"] = "ERROR"
            return state

        mark_llm(state)

        state["ai_response"] = msg
        state["ai_response_type"] = "AURA"
        state["ai_response_code"] = 101
        state["prompt_title"] = ""
        state["prompts"] = []
        state["stage"] = "NPI_SHOW_RESULTS"

        requested = interrupt({"prompt": msg, "stage": state["stage"]})
        state["csr_query"] = str(requested).strip()
        return state

    # Build SAME grid JSON as your other provider grids
    grid_list: List[Dict[str, Any]] = []
    for p in providers:
        prov_id = (
            p.get("providerId")
            or p.get("provId")
            or p.get("ProviderID")
            or ""
        )
        name_val = (
            p.get("name")
            or p.get("providerName")
            or p.get("fullName")
            or ""
        )
        addr = _format_address_from_provider(p)

        raw_network = p.get("networkStatus") or p.get("network") or ""
        raw_up = str(raw_network).upper()
        if raw_up in ("IN", "IN NETWORK"):
            net_str = "In Network"
        elif raw_up in ("OUT", "OUT NETWORK"):
            net_str = "Out Network"
        else:
            net_str = str(raw_network) if raw_network else ""

        grid_list.append({
            "ProviderID": str(prov_id),
            "Name": str(name_val),
            "Address": addr,
            "Network": net_str,
            "IsAcceptingNewMembers": p.get("isAcceptingNewMembers"),
            "PCPAssnInd": p.get("pcpAssnInd") or p.get("PCPAssnInd"),
            "DistanceInMiles": p.get("distance_mi") or p.get("distanceInMiles"),
        })

    state["providers_result"] = providers
    state["ai_response"] = json.dumps({"providers": grid_list}, default=str, separators=(",", ":"))
    state["ai_response_type"] = "AURA"
    state["ai_response_code"] = 107
    state["prompt_title"] = ""
    state["prompts"] = []
    state["stage"] = "SHOW_SPECIALIST_PROVIDER_LIST"

    requested = interrupt({"prompt": state["ai_response"], "stage": state["stage"]})
    state["csr_query"] = str(requested).strip()
    return state

# ---- Build graph ----

builder = StateGraph(PCPState)

builder.add_node("start", node_start)
builder.add_node("assign_pcp_ask_termination", node_assign_pcp_ask_termination)
builder.add_node("collect_termination_reason", node_collect_termination_reason)
builder.add_node("collect_knows_provider", node_collect_knows_provider)
builder.add_node("collect_provider_input", node_collect_provider_input)
builder.add_node("collect_no_flow_filters", node_collect_no_flow_filters)
builder.add_node("collect_filter_input", node_collect_filter_input)
builder.add_node("run_provider_search", node_run_provider_search)
builder.add_node("provider_interaction", node_provider_interaction)
builder.add_node("specialist_ask_service", node_specialist_ask_service)
builder.add_node("specialist_ask_filters", node_specialist_ask_filters)
builder.add_node("run_specialist_generic_search", node_run_specialist_generic_search)
builder.add_node("specialist_provider_address", node_specialist_provider_address)
builder.add_node("specialist_post_completion", node_specialist_post_completion)
builder.add_node("provider_id_only_warning", node_provider_id_only_warning)
builder.add_node("return_to_menu", node_return_to_menu)
builder.add_node("update_pcp", node_update_pcp)
builder.add_node("wait_next_followup", node_wait_next_followup)
builder.add_node("load_case", node_load_case)
builder.add_node("npi_ask_mode", node_npi_ask_mode)
builder.add_node("npi_ask_query", node_npi_ask_query)
builder.add_node("npi_run_search", node_npi_run_search)
builder.add_node("pcp_no_results_route", node_pcp_no_results_route)
builder.add_node("npi_followup_action", node_npi_followup_action)
builder.add_node("run_specialist_id_search", node_run_specialist_id_search)
builder.add_node("specialist_no_results_offer", node_specialist_no_results_offer)

builder.add_edge(START, "load_case")
builder.add_edge("load_case", "start")

# From start, conditionally branch based on menu choice
builder.add_conditional_edges(
    "start",
    path=route_from_menu,
    path_map={
        "assign_pcp": "assign_pcp_ask_termination",
        "specialist": "specialist_ask_service",
        "npi": "npi_ask_mode",
        "unsupported": END,
    },
)

builder.add_edge("assign_pcp_ask_termination", "collect_termination_reason")
builder.add_edge("collect_termination_reason", "collect_knows_provider")
builder.add_edge("specialist_ask_service", "specialist_ask_filters")
builder.add_edge("specialist_ask_filters", "run_specialist_generic_search")
# builder.add_edge("run_specialist_generic_search", "specialist_provider_address")
builder.add_conditional_edges(
    "run_specialist_generic_search",
    path=route_after_specialist_search,
    path_map={
        "providers": "specialist_provider_address",
        "offer": "specialist_no_results_offer",
        "npi": "npi_ask_mode",
        "menu": "return_to_menu",
        "stop": END,
    }
)

builder.add_conditional_edges(
    "specialist_no_results_offer",
    path=route_after_specialist_no_results_offer,
    path_map={
        "npi": "npi_ask_mode",
        "menu": "return_to_menu",
        "loop": "specialist_no_results_offer",
    }
)
# builder.add_edge("specialist_provider_address", "specialist_post_completion")
builder.add_edge("provider_id_only_warning", "provider_interaction")

builder.add_conditional_edges(
    "specialist_provider_address",
    path=route_after_specialist_provider_address,
    path_map={
        "completed": "specialist_post_completion",
        "loop": "specialist_provider_address",
        "stop": END, # or "return_to_menu" if we prefer
    },
)

builder.add_conditional_edges(
    "collect_knows_provider",
    path=route_knows_provider,
    path_map={
        "knows": "collect_provider_input",
        "unknown": "collect_no_flow_filters",
    },
)

builder.add_edge("collect_no_flow_filters", "run_provider_search")

builder.add_edge("collect_provider_input", "run_provider_search")
builder.add_edge("collect_filter_input", "run_provider_search")

builder.add_conditional_edges(
    "run_provider_search",
    path=route_after_provider_search_results,
    path_map={
        "found": "provider_interaction",
        "no_results": "pcp_no_results_route",
    },
)

builder.add_conditional_edges(
    "pcp_no_results_route",
    path=route_after_no_results_offer,
    path_map={
        "npi": "npi_ask_mode",
        "menu": "return_to_menu",
        "loop": "pcp_no_results_route",  # safest: re-run offer node again via no-results path
    },
)

builder.add_conditional_edges(
    "specialist_post_completion",
    path=route_after_specialist_completion,
    path_map={
        "menu": "return_to_menu",
        "end": END,
        "stop": END,
    },
)

builder.add_conditional_edges(
    "provider_interaction",
    path=route_after_provider_followup,
    path_map={
        "loop": "wait_next_followup",
        "assign": "update_pcp",
        "pid_only": "provider_id_only_warning",
    }
)

# After user says YES in specialist completion, we show menu via return_to_menu.
# IMPORTANT: once return_to_menu captures the next menu choice (resume value),
# we must route from it, otherwise graph will keep resuming on return_to_menu forever.
builder.add_conditional_edges(
    "return_to_menu",
    path=route_from_menu,
    path_map={
        "assign_pcp": "assign_pcp_ask_termination",
        "specialist": "specialist_ask_service",
        "npi": "npi_ask_mode", 
        "unsupported": END,
    },
)

builder.add_edge("npi_ask_mode", "npi_ask_query")
builder.add_edge("npi_ask_query", "npi_run_search")
# builder.add_edge("npi_search", "return_to_menu")

builder.add_conditional_edges(
    "npi_run_search",
    path=route_after_npi_run_search,
    path_map={
        "followup": "npi_followup_action",   # fallback mode -> user selects NPI/address
        "menu": "return_to_menu",            # menu mode -> your existing START menu behavior
    },
)


# After fallback followup selection:
# - If they selected NPI, node sets provider_id_override and knows_provider/raw_provider_input,
#   so we can route directly into provider search.
builder.add_conditional_edges(
    "npi_followup_action",
    path=route_after_npi_followup,
    path_map={
        "pcp": "run_provider_search",
        "specialist": "run_specialist_id_search",
        "loop": "npi_followup_action",
    },
)
builder.add_edge("run_specialist_id_search", "specialist_provider_address")

builder.add_edge("wait_next_followup", "provider_interaction")
builder.add_edge("update_pcp", END)

checkpointer = InMemorySaver()
graph = builder.compile(checkpointer=checkpointer)
===========================================
from app.graph.state import PCPState
from app.llm.parsers import (
    llm_route_menu_intent,
    llm_classify_yes_no
)

def route_from_menu(state: PCPState) -> str:
    text = (state.get("csr_query") or "").lower().strip()

    if not text:
        return "unsupported"
    return llm_route_menu_intent(text)


def route_knows_provider(state: PCPState) -> str:
    if state.get("knows_provider"):
        return "knows"
    return "unknown"

def route_after_provider_followup(state: PCPState) -> str:
    if state.get("last_followup_action") == "assign_pcp":
        return "assign"
    if state.get("last_followup_action") == "provider_id_only":
        return "pid_only"
    return "loop"

def route_after_specialist_completion(state: PCPState) -> str:
    st = (state.get("stage") or "").strip()
    st_up = st.upper()

    if st_up in ("CLOSED","STOP","END","ERROR"):
        return "end"
    
    if st_up in ("GO_MENU","START","MENU","GO_NPI"):
        return "menu"
    
    return "menu"

def route_after_specialist_provider_address(state: PCPState) -> str:
    # Only go to post-completion logic if we truly completed address inquiry
    if (state.get("stage") or "").strip().upper() == "COMPLETED":
        return "completed"
    return "loop"

# def route_after_specialist_search(state: PCPState) -> str:
#     # If we set GO_NPI in no-results case, route to NPI flow
#     if (state.get("stage") or "").strip() == "GO_NPI":
#         return "npi"
#     # If providers exist, continue normally
#     if state.get("providers_result"):
#         return "providers"
#     # defensive: treat missing providers as stop (avoid loops)
#     return "stop"
def route_after_specialist_search(state: PCPState) -> str:
    st = (state.get("stage") or "").strip().upper()

    if st == "SPECIALIST_NO_RESULTS_OFFER_NPI":
        return "offer"
    
    if st == "GO_NPI":
        return "npi"

    if st in ("GO_MENU", "START", "MENU"):
        return "menu"

    if state.get("providers_result"):
        return "providers"

    return "stop"

def route_after_specialist_no_results_offer(state: PCPState) -> str:
    """
    After we asked: "No specialist results -> try NPI web search?"
    """
    txt = (state.get("csr_query") or "").strip()
    ans = llm_classify_yes_no(txt)
    if ans == "yes":
        return "npi"
    if ans == "no":
        return "menu"
    return "loop"

def route_after_provider_search_results(state: PCPState) -> str:
    """
    After run_provider_search:
      - if providers exist -> "found"
      - if none -> "no_results"
    """
    providers = state.get("providers_result") or []
    if isinstance(providers, list) and len(providers) > 0:
        return "found"
    return "no_results"


def route_after_no_results_offer(state: PCPState) -> str:
    """
    After we ask: "Do you want NPI web search?"
    Use Horizon to classify yes/no (no hardcoded match).
    """
    txt = (state.get("csr_query") or "").strip()
    ans = llm_classify_yes_no(txt)
    if ans == "yes":
        return "npi"
    if ans == "no":
        return "menu"
    # unknown -> re-ask offer (safe)
    return "loop"

def route_after_npi_run_search(state: PCPState) -> str:
    """
    If NPI was entered from menu -> keep current behavior (results + menu).
    If NPI was entered from fallback -> go to followup node (user selects NPI/address).
    """
    origin = (state.get("npi_origin") or "menu").strip().lower()
    return "followup" if origin == "fallback" else "menu"

def route_after_npi_followup(state: PCPState) -> str:
    tgt = (state.get("npi_target_flow") or "pcp").strip().lower()
    # if we have an override id, proceed; otherwise keep looping in npi followup
    if not (state.get("provider_id_override") or ""):
        return "loop"
    return "specialist" if tgt == "specialist" else "pcp"
